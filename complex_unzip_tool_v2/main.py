"""Main CLI interface for Complex Unzip Tool v2."""

import os
import shutil
import sys
import typer
from typing import List, Optional, Annotated

from .modules import (
    file_utils,
    archive_utils,
    const,
    password_util,
)
from .modules.rich_utils import (
    init_statistics,
    print_header,
    print_step,
    print_info,
    print_success,
    print_warning,
    print_error,
    print_archive_group_summary,
    print_remaining_groups_warning,
    print_all_processed_success,
    print_final_completion,
    print_separator,
    create_spinner,
    print_extraction_header,
    print_empty_line,
    print_version,
    print_general,
    print_file_path,
    create_extraction_progress,
    create_file_operation_progress,
    print_major_section_break,
    print_minor_section_break,
    print_processing_separator,
)

app = typer.Typer(
    help="Complex Unzip Tool v2 - Advanced Archive Extraction Utility å¤æ‚è§£å‹å·¥å…·v2 - é«˜çº§æ¡£æ¡ˆæå–å®ç”¨ç¨‹åº"
)


def _ask_for_user_input_and_exit() -> None:
    """Ask for random user input before exiting the application."""
    # Only ask for input in standalone builds (PyInstaller frozen executables)
    if getattr(sys, "frozen", False):
        input("Press Enter to exit... æŒ‰å›è½¦é”®é€€å‡º...")
    sys.exit(0)


@app.callback(invoke_without_command=True)
def main_callback(
    ctx: typer.Context,
    paths: Annotated[
        Optional[List[str]],
        typer.Argument(help="Archive paths to extract è¦æå–çš„æ¡£æ¡ˆè·¯å¾„"),
    ] = None,
    version: bool = typer.Option(
        False, "--version", "-v", help="Show version information æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"
    ),
    permanent_delete: bool = typer.Option(
        False,
        "--permanent-delete",
        "-pd",
        help="Permanently delete original files instead of moving to recycle bin æ°¸ä¹…åˆ é™¤åŸå§‹æ–‡ä»¶è€Œä¸æ˜¯ç§»åŠ¨åˆ°å›æ”¶ç«™",
    ),
) -> None:
    """Complex Unzip Tool v2 - Advanced Archive Extraction Utility å¤æ‚è§£å‹å·¥å…·v2 - é«˜çº§æ¡£æ¡ˆæå–å®ç”¨ç¨‹åº"""
    if version:
        from . import __version__

        print_version(__version__)
        _ask_for_user_input_and_exit()

    # If no command is provided, run the default extract command
    if ctx.invoked_subcommand is None:
        if paths:
            # Call extract_files directly instead of extract command
            extract_files(paths, use_recycle_bin=not permanent_delete)
        else:
            # Show help when no paths are provided
            print_general(ctx.get_help())
            _ask_for_user_input_and_exit()


@app.command()
def version() -> None:
    """Show version information æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    from . import __version__

    print_version(__version__)
    _ask_for_user_input_and_exit()


def extract(
    paths: Annotated[
        List[str],
        typer.Argument(help="Paths to the archives to extract è¦æå–çš„æ¡£æ¡ˆè·¯å¾„"),
    ],
    permanent_delete: bool = typer.Option(
        False,
        "--permanent-delete",
        "-pd",
        help="Permanently delete original files instead of moving to recycle bin æ°¸ä¹…åˆ é™¤åŸå§‹æ–‡ä»¶è€Œä¸æ˜¯ç§»åŠ¨åˆ°å›æ”¶ç«™",
    ),
) -> None:
    """Extract files from an archive ä»æ¡£æ¡ˆä¸­æå–æ–‡ä»¶"""
    extract_files(paths, use_recycle_bin=not permanent_delete)


def extract_files(paths: List[str], use_recycle_bin: bool = True) -> None:
    """Shared extraction logic å…±äº«æå–é€»è¾‘"""

    # Initialize statistics tracking
    init_statistics()

    # Header with fancy border
    print_header("ğŸš€ Starting Complex Unzip Tool v2 å¯åŠ¨å¤æ‚è§£å‹å·¥å…·v2")

    # Step 1: Setup output folder è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹
    print_step(1, "ğŸ“ Setting up output folder è®¾ç½®è¾“å‡ºæ–‡ä»¶å¤¹")

    if os.path.isdir(paths[0]):
        output_folder = os.path.join(paths[0], const.OUTPUT_FOLDER)
    else:
        output_folder = os.path.join(os.path.dirname(paths[0]), const.OUTPUT_FOLDER)

    os.makedirs(output_folder, exist_ok=True)
    print_success("Output folder created è¾“å‡ºæ–‡ä»¶å¤¹å·²åˆ›å»º:")
    print_file_path(f"ğŸ“‚ {output_folder}")
    print_minor_section_break()

    # Step 2: Load passwords åŠ è½½å¯†ç 
    print_step(2, "ğŸ”‘ Loading passwords åŠ è½½å¯†ç ")

    loader = create_spinner("Loading passwords æ­£åœ¨åŠ è½½å¯†ç ...")
    loader.start()
    passwordBook = password_util.load_all_passwords(paths)
    user_provided_passwords = []
    loader.stop()

    print_success(
        f"Loaded {len(passwordBook.get_passwords())} unique passwords å·²åŠ è½½ {len(passwordBook.get_passwords())} ä¸ªå”¯ä¸€å¯†ç "
    )
    print_minor_section_break()

    # Step 3: Scanning files æ‰«ææ–‡ä»¶
    print_step(3, "ğŸ“‚ Scanning files æ‰«ææ–‡ä»¶")

    print_info("Extracting files from æ­£åœ¨æå–æ–‡ä»¶è‡ª:")
    for i, path in enumerate(paths):
        print_file_path(f"{i+1}. {path}")

    loader = create_spinner("Scanning directory æ­£åœ¨æ‰«æç›®å½•...")
    loader.start()
    contents = file_utils.read_dir(paths)
    loader.stop()

    print_success("Scan completed! æ‰«æå®Œæˆï¼")
    print_minor_section_break()

    # Step 4: Uncloak file extensions æ­ç¤ºæ–‡ä»¶æ‰©å±•å
    print_step(4, "ğŸ­ Uncloaking file extensions æ­ç¤ºæ–‡ä»¶æ‰©å±•å")

    loader = create_spinner("Uncloaking file extensions æ­£åœ¨æ­ç¤ºæ–‡ä»¶æ‰©å±•å...")
    loader.start()
    contents = file_utils.uncloak_file_extensions(contents)
    loader.stop()

    print_success("File extensions uncloaked æ–‡ä»¶æ‰©å±•åå·²æ­ç¤º")
    print_minor_section_break()

    # Step 5: Create archive groups åˆ›å»ºæ¡£æ¡ˆç»„
    print_step(5, "ğŸ“‹ Creating archive groups åˆ›å»ºæ¡£æ¡ˆç»„")

    loader = create_spinner("Analyzing archive groups æ­£åœ¨åˆ†ææ¡£æ¡ˆç»„...")
    loader.start()
    groups = file_utils.create_groups_by_name(contents)
    loader.stop()

    print_success(f"Created {len(groups)} archive groups å·²åˆ›å»º {len(groups)} ä¸ªæ¡£æ¡ˆç»„")
    print_minor_section_break()

    # Step 6: Processing archive groups å¤„ç†æ¡£æ¡ˆç»„
    print_step(6, "âš™ï¸ Processing archive groups å¤„ç†æ¡£æ¡ˆç»„")

    # Display groups with fancy formatting - use rich function instead
    print_archive_group_summary(groups)
    print_minor_section_break()

    # Step 7: Processing single archives first é¦–å…ˆå¤„ç†å•ä¸€æ¡£æ¡ˆ
    print_step(7, "ğŸ”§ Processing single archives first é¦–å…ˆå¤„ç†å•ä¸€æ¡£æ¡ˆ")

    print_info(
        "ğŸ“ Processing single archive to extract containers å¤„ç†å•ä¸€æ¡£æ¡ˆä»¥æå–å®¹å™¨..."
    )

    # Get single archives for progress tracking
    single_archives = [group for group in groups if not group.isMultiPart]

    if single_archives:
        # Start extraction progress
        extraction_progress = create_extraction_progress("Single Archives")
        extraction_progress.start(len(single_archives))

        for group in single_archives.copy():
            extraction_progress.start_group(group.name, len(group.files))

            print_extraction_header(f"ğŸ—‚ï¸ Extracting single archive: {group.name}")

            # Check if the main archive file exists
            if not os.path.exists(group.mainArchiveFile):
                print_error(
                    f"Main archive file not found ä¸»æ¡£æ¡ˆæ–‡ä»¶æœªæ‰¾åˆ°: {os.path.basename(group.mainArchiveFile)}",
                    2,
                )

                # Try to find an alternative main archive in the group
                if group.try_set_alternative_main_archive():
                    print_info(
                        f"Using alternative main archive ä½¿ç”¨å¤‡ç”¨ä¸»æ¡£æ¡ˆ: {os.path.basename(group.mainArchiveFile)}",
                        2,
                    )
                else:
                    print_error(
                        f"No valid archive files found in group ç»„ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆæ¡£æ¡ˆæ–‡ä»¶: {group.name}",
                        2,
                    )
                    groups.remove(group)
                    extraction_progress.complete_group(success=False)
                    print_minor_section_break()
                    continue

            dir = os.path.dirname(group.mainArchiveFile)
            extraction_temp_path = os.path.join(dir, f"temp.{group.name}")
            print_info("ğŸ“‚ Extraction temp path æå–ä¸´æ—¶è·¯å¾„:", 2)
            print_file_path(extraction_temp_path, 3)

            try:
                # Start loading indicator for extraction
                loader = create_spinner(
                    f"Extracting {group.name} æ­£åœ¨æå– {group.name}..."
                )
                loader.start()

                result = archive_utils.extract_nested_archives(
                    archive_path=group.mainArchiveFile,
                    output_path=extraction_temp_path,
                    password_list=passwordBook.get_passwords(),
                    max_depth=10,
                    cleanup_archives=True,
                    loading_indicator=loader,
                    active_progress_bars=[extraction_progress],
                    use_recycle_bin=False,
                )

                loader.stop()

                # Check if extraction was successful and result contains expected data
                if result and result.get("success", False):
                    # add user provided passwords
                    user_provided_passwords.extend(
                        result.get("user_provided_passwords", [])
                    )

                    # Successfully extracted nested archives
                    final_files_raw = result.get("final_files", [])

                    # Type guard to ensure we have a list
                    if isinstance(final_files_raw, list):
                        final_files = (
                            final_files_raw.copy()
                        )  # Make a copy to safely modify

                        print_success(
                            f"Successfully extracted æˆåŠŸæå–: {group.name}", 2
                        )
                        print_info("Checking extracted files æ­£åœ¨æ£€æŸ¥æå–çš„æ–‡ä»¶...", 2)
                        print_processing_separator()

                        # Process each extracted file
                        files_to_remove = []
                        for file_path in final_files:
                            if os.path.exists(file_path):
                                if file_utils.add_file_to_groups(file_path, groups):
                                    print_success(
                                        f"ğŸ“¦ {os.path.basename(file_path)} â†’ moved to group location ç§»åŠ¨åˆ°ç»„ä½ç½®",
                                        3,
                                    )
                                    files_to_remove.append(file_path)
                            else:
                                print_warning(
                                    f"File not found æ–‡ä»¶æœªæ‰¾åˆ°: {os.path.basename(file_path)}",
                                    3,
                                )
                                files_to_remove.append(file_path)

                        # Remove processed files from the list
                        for file_path in files_to_remove:
                            final_files.remove(file_path)

                        # Move remaining files to output folder
                        if final_files:
                            print_processing_separator()
                            print_info(
                                f"Moving {len(final_files)} remaining files to output folder",
                                2,
                            )
                            print_info(
                                f"æ­£åœ¨å°† {len(final_files)} ä¸ªå‰©ä½™æ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºæ–‡ä»¶å¤¹...",
                                3,
                            )

                            # Create file operation progress
                            file_progress = create_file_operation_progress(
                                "Moving Files"
                            )
                            file_progress.start(len(final_files))

                            moved_files = file_utils.move_files_preserving_structure(
                                final_files,
                                extraction_temp_path,
                                output_folder,
                                progress_callback=lambda: file_progress.update(1),
                            )

                            file_progress.stop()
                            print_success(
                                f"Moved {len(moved_files)} files successfully æˆåŠŸç§»åŠ¨ {len(moved_files)} ä¸ªæ–‡ä»¶",
                                2,
                            )

                        print_processing_separator()
                        # Remove the original archive file
                        try:
                            if os.path.exists(group.mainArchiveFile):
                                success = file_utils.safe_remove(
                                    group.mainArchiveFile,
                                    use_recycle_bin=use_recycle_bin,
                                    error_callback=print_error,
                                )
                                if success:
                                    if use_recycle_bin:
                                        print_success(
                                            "Moved original archive to recycle bin å·²å°†åŸå§‹æ¡£æ¡ˆç§»è‡³å›æ”¶ç«™:",
                                            2,
                                        )
                                    else:
                                        print_success(
                                            "Removed original archive å·²åˆ é™¤åŸå§‹æ¡£æ¡ˆ:",
                                            2,
                                        )
                                    print_file_path(
                                        os.path.basename(group.mainArchiveFile), 3
                                    )
                        except Exception as e:
                            print_warning(
                                "Could not remove original archive æ— æ³•åˆ é™¤åŸå§‹æ¡£æ¡ˆ:", 2
                            )
                            print_error(f"{group.mainArchiveFile}: {e}", 3)

                        # Remove the temporary extraction folder
                        try:
                            if os.path.exists(extraction_temp_path):
                                shutil.rmtree(extraction_temp_path)
                                print_success(
                                    "Cleaned up temporary folder å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹", 2
                                )
                        except Exception as e:
                            print_warning(
                                f"Could not remove temp folder æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹: {e}",
                                2,
                            )

                        # Remove the subfolder for group belongs, if not related to output folder
                        try:
                            # Get the directory containing the archive files
                            archive_dir = os.path.dirname(group.mainArchiveFile)

                            # Only remove if it's not the output folder and doesn't contain the output folder
                            if os.path.abspath(archive_dir) != os.path.abspath(
                                output_folder
                            ) and not os.path.abspath(output_folder).startswith(
                                os.path.abspath(archive_dir) + os.sep
                            ):
                                # Check if directory is empty (or only contains hidden files/folders)
                                remaining_items = [
                                    item
                                    for item in os.listdir(archive_dir)
                                    if not item.startswith(".")
                                    and item != const.OUTPUT_FOLDER
                                ]

                                if not remaining_items:
                                    shutil.rmtree(archive_dir)
                                    print_success(
                                        "Removed empty archive subfolder å·²åˆ é™¤ç©ºæ¡£æ¡ˆå­æ–‡ä»¶å¤¹:",
                                        2,
                                    )
                                    print_file_path(os.path.basename(archive_dir), 3)
                                else:
                                    print_info(
                                        "Archive subfolder kept (contains other files) æ¡£æ¡ˆå­æ–‡ä»¶å¤¹ä¿ç•™ï¼ˆåŒ…å«å…¶ä»–æ–‡ä»¶ï¼‰:",
                                        2,
                                    )
                                    print_file_path(os.path.basename(archive_dir), 3)
                            else:
                                print_info(
                                    "Archive subfolder contains output folder, not removed æ¡£æ¡ˆå­æ–‡ä»¶å¤¹åŒ…å«è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œæœªåˆ é™¤",
                                    2,
                                )
                        except Exception as e:
                            print_warning(
                                f"Could not remove archive subfolder æ— æ³•åˆ é™¤æ¡£æ¡ˆå­æ–‡ä»¶å¤¹: {e}",
                                2,
                            )

                        # Remove the group from processing
                        groups.remove(group)
                        extraction_progress.complete_group(success=True)
                        print_success("Processing completed å¤„ç†å®Œæˆ", 2)
                        print_minor_section_break()

                    else:
                        print_error("Expected list of files æœŸæœ›æ–‡ä»¶åˆ—è¡¨", 2)
                        print_error(f"Got {type(final_files_raw)} for {group.name}", 3)
                        groups.remove(group)
                        extraction_progress.complete_group(success=False)

                else:
                    print_error(f"Failed to extract æå–å¤±è´¥: {group.name}", 2)
                    if os.path.exists(extraction_temp_path):
                        shutil.rmtree(extraction_temp_path)
                    groups.remove(group)
                    extraction_progress.complete_group(success=False)
                    print_minor_section_break()

            except Exception as e:
                print_error(f"Error processing å¤„ç†é”™è¯¯: {group.name}", 2)
                print_error(f"Error details é”™è¯¯è¯¦æƒ…: {e}", 3)

                # Try alternative main archives if available
                if group.try_set_alternative_main_archive():
                    print_info(
                        f"Trying alternative main archive å°è¯•å¤‡ç”¨ä¸»æ¡£æ¡ˆ: {os.path.basename(group.mainArchiveFile)}",
                        2,
                    )

                    # Update the extraction temp path for the new main archive
                    new_dir = os.path.dirname(group.mainArchiveFile)
                    new_extraction_temp_path = os.path.join(
                        new_dir, f"temp.{group.name}"
                    )

                    # Clean up the old temp folder if it exists
                    try:
                        if os.path.exists(extraction_temp_path):
                            shutil.rmtree(extraction_temp_path)
                    except Exception:
                        pass

                    try:
                        # Start loading indicator for extraction
                        retry_loader = create_spinner(
                            f"Retrying extraction with alternative archive ä½¿ç”¨å¤‡ç”¨æ¡£æ¡ˆé‡æ–°æå– {group.name}..."
                        )
                        retry_loader.start()

                        retry_result = archive_utils.extract_nested_archives(
                            archive_path=group.mainArchiveFile,
                            output_path=new_extraction_temp_path,
                            password_list=passwordBook.get_passwords(),
                            max_depth=10,
                            cleanup_archives=True,
                            loading_indicator=retry_loader,
                            active_progress_bars=[extraction_progress],
                            use_recycle_bin=False,
                        )

                        retry_loader.stop()

                        # Check if retry extraction was successful
                        if retry_result and retry_result.get("success", False):
                            print_success(
                                f"Alternative archive extraction succeeded å¤‡ç”¨æ¡£æ¡ˆæå–æˆåŠŸ: {group.name}",
                                2,
                            )
                            extraction_progress.complete_group(success=True)
                            print_minor_section_break()
                            continue  # Skip the removal and continue with next group
                        else:
                            print_error(
                                f"Alternative archive extraction also failed å¤‡ç”¨æ¡£æ¡ˆæå–ä¹Ÿå¤±è´¥: {group.name}",
                                2,
                            )
                            # Clean up temp folder if it exists
                            if os.path.exists(new_extraction_temp_path):
                                shutil.rmtree(new_extraction_temp_path)

                    except Exception as retry_e:
                        print_error(f"Error during retry é‡è¯•æ—¶å‡ºé”™: {retry_e}", 3)
                        # Clean up temp folder if it exists
                        if os.path.exists(new_extraction_temp_path):
                            try:
                                shutil.rmtree(new_extraction_temp_path)
                            except Exception:
                                pass
                else:
                    print_warning(
                        f"No alternative archives available for group ç»„ä¸­æ²¡æœ‰å¤‡ç”¨æ¡£æ¡ˆ: {group.name}",
                        2,
                    )

                # Clean up original temp folder if it still exists
                try:
                    if os.path.exists(extraction_temp_path):
                        shutil.rmtree(extraction_temp_path)
                except Exception:
                    pass
                finally:
                    groups.remove(group)
                    extraction_progress.complete_group(success=False)
                    print_minor_section_break()
                continue

            print_separator()
            print_empty_line()

        extraction_progress.stop()
    else:
        print_info("No single archives found æœªæ‰¾åˆ°å•ä¸€æ¡£æ¡ˆ")
        print_minor_section_break()

    # add user provided passwords to password book
    if user_provided_passwords:
        passwordBook.add_passwords(user_provided_passwords)

    # Step 8: Then handle multipart archives ç„¶åå¤„ç†å¤šéƒ¨åˆ†æ¡£æ¡ˆ
    print_step(8, "ğŸ”— Processing multipart archives å¤„ç†å¤šéƒ¨åˆ†æ¡£æ¡ˆ")

    # Get multipart archives for progress tracking
    multipart_archives = [group for group in groups if group.isMultiPart]

    if multipart_archives:
        # Start extraction progress for multipart archives
        multipart_progress = create_extraction_progress("Multipart Archives")
        multipart_progress.start(len(multipart_archives))

        for group in multipart_archives.copy():
            multipart_progress.start_group(group.name, len(group.files))

            print_extraction_header(f"ğŸ“š Handling multipart archive: {group.name}")

            # Check if the main archive file exists
            if not os.path.exists(group.mainArchiveFile):
                print_error(
                    f"Main multipart archive file not found ä¸»å¤šéƒ¨åˆ†æ¡£æ¡ˆæ–‡ä»¶æœªæ‰¾åˆ°: {os.path.basename(group.mainArchiveFile)}",
                    2,
                )

                # Try to find an alternative main archive in the group
                if group.try_set_alternative_main_archive():
                    print_info(
                        f"Using alternative main multipart archive ä½¿ç”¨å¤‡ç”¨ä¸»å¤šéƒ¨åˆ†æ¡£æ¡ˆ: {os.path.basename(group.mainArchiveFile)}",
                        2,
                    )
                else:
                    print_error(
                        f"No valid multipart archive files found in group ç»„ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå¤šéƒ¨åˆ†æ¡£æ¡ˆæ–‡ä»¶: {group.name}",
                        2,
                    )
                    groups.remove(group)
                    multipart_progress.complete_group(success=False)
                    print_minor_section_break()
                    continue

            dir = os.path.dirname(group.mainArchiveFile)
            extraction_temp_path = os.path.join(dir, f"temp.{group.name}")

            try:
                # Start loading indicator for extraction
                loader = create_spinner(
                    f"Extracting multipart {group.name} æ­£åœ¨æå–å¤šéƒ¨åˆ† {group.name}..."
                )
                loader.start()

                result = archive_utils.extract_nested_archives(
                    archive_path=group.mainArchiveFile,
                    output_path=extraction_temp_path,
                    password_list=passwordBook.get_passwords(),
                    max_depth=10,
                    cleanup_archives=True,
                    loading_indicator=loader,
                    active_progress_bars=[multipart_progress],
                    use_recycle_bin=False,
                )

                loader.stop()

                if result and result.get("success", False):
                    # add user provided passwords
                    user_provided_passwords.extend(
                        result.get("user_provided_passwords", [])
                    )

                    # Successfully extracted nested archives
                    final_files_raw = result.get("final_files", [])

                    # Type guard to ensure we have a list
                    if isinstance(final_files_raw, list):
                        print_success(
                            f"Successfully extracted æˆåŠŸæå–: {group.name}", 2
                        )
                        print_processing_separator()

                        final_files = (
                            final_files_raw.copy()
                        )  # Make a copy to safely modify

                        # Move files to output folder
                        if final_files:
                            print_info(
                                f"Moving {len(final_files)} files to output folder", 2
                            )
                            print_info(
                                f"æ­£åœ¨å°† {len(final_files)} ä¸ªæ–‡ä»¶ç§»åŠ¨åˆ°è¾“å‡ºæ–‡ä»¶å¤¹...",
                                3,
                            )

                            # Create file operation progress
                            file_progress = create_file_operation_progress(
                                "Moving Files"
                            )
                            file_progress.start(len(final_files))

                            moved_files = file_utils.move_files_preserving_structure(
                                final_files,
                                extraction_temp_path,
                                output_folder,
                                progress_callback=lambda: file_progress.update(1),
                            )

                            file_progress.stop()
                            print_success(
                                f"Moved {len(moved_files)} files successfully æˆåŠŸç§»åŠ¨ {len(moved_files)} ä¸ªæ–‡ä»¶",
                                2,
                            )

                            print_processing_separator()
                            # Remove the original archive file
                            if use_recycle_bin:
                                print_info(
                                    f"Moving {len(group.files)} archive parts to recycle bin æ­£åœ¨å°† {len(group.files)} ä¸ªæ¡£æ¡ˆéƒ¨åˆ†ç§»è‡³å›æ”¶ç«™...",
                                    2,
                                )
                            else:
                                print_info(
                                    f"Removing {len(group.files)} archive parts æ­£åœ¨åˆ é™¤ {len(group.files)} ä¸ªæ¡£æ¡ˆéƒ¨åˆ†...",
                                    2,
                                )
                            try:
                                for archive_file in group.files:
                                    if os.path.exists(archive_file):
                                        success = file_utils.safe_remove(
                                            archive_file,
                                            use_recycle_bin=use_recycle_bin,
                                            error_callback=print_error,
                                        )
                                        if success:
                                            print_success(
                                                f"âœ“ {os.path.basename(archive_file)}", 3
                                            )
                            except Exception as e:
                                print_warning(
                                    f"Could not remove some archive parts æ— æ³•åˆ é™¤æŸäº›æ¡£æ¡ˆéƒ¨åˆ†: {e}",
                                    2,
                                )

                            # Remove the temporary extraction folder
                            try:
                                if os.path.exists(extraction_temp_path):
                                    shutil.rmtree(extraction_temp_path)
                                    print_success(
                                        "Cleaned up temporary folder å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤¹",
                                        2,
                                    )
                            except Exception as e:
                                print_warning(
                                    f"Could not remove temp folder æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹: {e}",
                                    2,
                                )

                            # Remove the subfolder for group belongs, if not related to output folder
                            try:
                                # Get the directory containing the archive files
                                archive_dir = os.path.dirname(group.mainArchiveFile)

                                # Only remove if it's not the output folder and doesn't contain the output folder
                                if os.path.abspath(archive_dir) != os.path.abspath(
                                    output_folder
                                ) and not os.path.abspath(output_folder).startswith(
                                    os.path.abspath(archive_dir) + os.sep
                                ):
                                    # Check if directory is empty (or only contains hidden files/folders)
                                    remaining_items = [
                                        item
                                        for item in os.listdir(archive_dir)
                                        if not item.startswith(".")
                                        and item != const.OUTPUT_FOLDER
                                    ]

                                    if not remaining_items:
                                        shutil.rmtree(archive_dir)
                                        print_success(
                                            "Removed empty archive subfolder å·²åˆ é™¤ç©ºæ¡£æ¡ˆå­æ–‡ä»¶å¤¹:",
                                            2,
                                        )
                                        print_file_path(
                                            os.path.basename(archive_dir), 3
                                        )
                                    else:
                                        print_info(
                                            "Archive subfolder kept (contains other files) æ¡£æ¡ˆå­æ–‡ä»¶å¤¹ä¿ç•™ï¼ˆåŒ…å«å…¶ä»–æ–‡ä»¶ï¼‰:",
                                            2,
                                        )
                                        print_file_path(
                                            os.path.basename(archive_dir), 3
                                        )
                                else:
                                    print_info(
                                        "Archive subfolder contains output folder, not removed æ¡£æ¡ˆå­æ–‡ä»¶å¤¹åŒ…å«è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œæœªåˆ é™¤",
                                        2,
                                    )
                            except Exception as e:
                                print_warning(
                                    f"Could not remove archive subfolder æ— æ³•åˆ é™¤æ¡£æ¡ˆå­æ–‡ä»¶å¤¹: {e}",
                                    2,
                                )

                            # Remove the group from processing
                            groups.remove(group)
                            multipart_progress.complete_group(success=True)
                            print_success("Processing completed å¤„ç†å®Œæˆ", 2)
                            print_minor_section_break()

                    else:
                        print_error("Expected list of files æœŸæœ›æ–‡ä»¶åˆ—è¡¨", 2)
                        print_error(f"Got {type(final_files_raw)} for {group.name}", 3)
                        groups.remove(group)
                        multipart_progress.complete_group(success=False)
                        print_minor_section_break()
                else:
                    print_error(f"Failed to extract æå–å¤±è´¥: {group.name}", 2)
                    if os.path.exists(extraction_temp_path):
                        shutil.rmtree(extraction_temp_path)
                    groups.remove(group)
                    multipart_progress.complete_group(success=False)
                    print_minor_section_break()

            except Exception as e:
                print_error(f"Error processing å¤„ç†é”™è¯¯: {group.name}", 2)
                print_error(f"Error details é”™è¯¯è¯¦æƒ…: {e}", 3)

                # Try alternative main archives if available
                if group.try_set_alternative_main_archive():
                    print_info(
                        f"Trying alternative main archive å°è¯•å¤‡ç”¨ä¸»æ¡£æ¡ˆ: {os.path.basename(group.mainArchiveFile)}",
                        2,
                    )

                    # Update the extraction temp path for the new main archive
                    new_dir = os.path.dirname(group.mainArchiveFile)
                    new_extraction_temp_path = os.path.join(
                        new_dir, f"temp.{group.name}"
                    )

                    # Clean up the old temp folder if it exists
                    try:
                        if os.path.exists(extraction_temp_path):
                            shutil.rmtree(extraction_temp_path)
                    except Exception:
                        pass

                    try:
                        # Start loading indicator for extraction
                        retry_loader = create_spinner(
                            f"Retrying multipart extraction é‡æ–°å°è¯•å¤šéƒ¨åˆ†æå– {group.name}..."
                        )
                        retry_loader.start()

                        retry_result = archive_utils.extract_nested_archives(
                            archive_path=group.mainArchiveFile,
                            output_path=new_extraction_temp_path,
                            password_list=passwordBook.get_passwords(),
                            max_depth=10,
                            cleanup_archives=True,
                            loading_indicator=retry_loader,
                            active_progress_bars=[multipart_progress],
                            use_recycle_bin=False,
                        )

                        retry_loader.stop()

                        # Check if retry extraction was successful
                        if retry_result and retry_result.get("success", False):
                            print_success(
                                f"Alternative multipart archive extraction succeeded å¤‡ç”¨å¤šéƒ¨åˆ†æ¡£æ¡ˆæå–æˆåŠŸ: {group.name}",
                                2,
                            )
                            multipart_progress.complete_group(success=True)
                            print_minor_section_break()
                            continue  # Skip the removal and continue with next group
                        else:
                            print_error(
                                f"Alternative multipart archive extraction also failed å¤‡ç”¨å¤šéƒ¨åˆ†æ¡£æ¡ˆæå–ä¹Ÿå¤±è´¥: {group.name}",
                                2,
                            )
                            # Clean up temp folder if it exists
                            if os.path.exists(new_extraction_temp_path):
                                shutil.rmtree(new_extraction_temp_path)

                    except Exception as retry_e:
                        print_error(
                            f"Error during multipart retry å¤šéƒ¨åˆ†é‡è¯•æ—¶å‡ºé”™: {retry_e}",
                            3,
                        )
                        # Clean up temp folder if it exists
                        if os.path.exists(new_extraction_temp_path):
                            try:
                                shutil.rmtree(new_extraction_temp_path)
                            except Exception:
                                pass
                else:
                    print_warning(
                        f"No alternative multipart archives available for group ç»„ä¸­æ²¡æœ‰å¤‡ç”¨å¤šéƒ¨åˆ†æ¡£æ¡ˆ: {group.name}",
                        2,
                    )

                # Clean up original temp folder if it still exists
                try:
                    if os.path.exists(extraction_temp_path):
                        shutil.rmtree(extraction_temp_path)
                except Exception:
                    pass
                finally:
                    groups.remove(group)
                    multipart_progress.complete_group(success=False)
                    print_minor_section_break()
                continue

            print_separator()
            print_empty_line()

        multipart_progress.stop()
    else:
        print_info("No multipart archives found æœªæ‰¾åˆ°å¤šéƒ¨åˆ†æ¡£æ¡ˆ")
        print_minor_section_break()

    # add user provided password to password book
    if user_provided_passwords:
        passwordBook.add_passwords(user_provided_passwords)

    # Step 9: Final summary æœ€ç»ˆæ‘˜è¦
    print_step(9, "ğŸ“Š Final summary æœ€ç»ˆæ‘˜è¦")

    # Show remaining unable to process files
    if groups:
        print_remaining_groups_warning(groups)
    else:
        print_all_processed_success()

    print_minor_section_break()
    # save user provided passwords only if there are changes
    if passwordBook.has_unsaved_changes():
        print_info("ğŸ’¾ Saving passwords æ­£åœ¨ä¿å­˜å¯†ç ...")
        passwordBook.save_passwords()
    else:
        print_info("ğŸ“ No new passwords to save æ²¡æœ‰æ–°å¯†ç éœ€è¦ä¿å­˜")

    print_major_section_break()
    # Footer with fancy border
    print_final_completion(output_folder)

    # Ask for random user input before exit
    _ask_for_user_input_and_exit()


def cli() -> None:
    """Command line interface entry point å‘½ä»¤è¡Œç•Œé¢å…¥å£ç‚¹"""
    app()


def main() -> None:
    """Entry point for the application åº”ç”¨ç¨‹åºå…¥å£ç‚¹"""
    try:
        cli()
    except KeyboardInterrupt:
        print_error("\nOperation cancelled by user æ“ä½œè¢«ç”¨æˆ·å–æ¶ˆ")
        _ask_for_user_input_and_exit()
    except Exception as e:
        print_error(f"Unexpected error æ„å¤–é”™è¯¯: {e}")
        _ask_for_user_input_and_exit()


if __name__ == "__main__":
    main()
