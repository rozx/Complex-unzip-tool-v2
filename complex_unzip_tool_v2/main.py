"""
Complex Unzip Tool v2 - Advanced zip file management
Â§çÊùÇËß£ÂéãÂ∑•ÂÖ∑ v2 - È´òÁ∫ßÂéãÁº©Êñá‰ª∂ÁÆ°ÁêÜÂ∑•ÂÖ∑

A sop                    i          safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂") else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")rename_errors:
            for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")
    
    if verbose:     safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂") else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")     for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")f rename_errors:
            for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")f rename_errors:
            for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")       safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂") else:
        safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")       safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")       safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")       safe_safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")icated bilingual tool for analyzing and grouping archive files.
"""

import argparse
import shutil
import sys
import os
import re
from pathlib import Path
from typing import List

# Fix Windows console encoding for Unicode characters
if sys.platform.startswith('win'):
    try:
        # Set UTF-8 code page for Windows console
        os.system('chcp 65001 >nul 2>&1')
    except Exception:
        pass

from .file_collector import collect_all_files
from .file_grouper import group_files_by_subfolder, group_files_by_priority
from .display_utils import display_file_groups
from .path_validator import validate_paths
from .password_manager import load_password_book, display_password_info, save_new_passwords
from .file_renamer import detect_cloaked_files, rename_cloaked_files, display_rename_suggestions
from .console_utils import safe_print
from .archive_extractor import (
    ExtractionResult, find_main_archive_in_group, extract_with_7z, 
    extract_nested_archives, create_completed_structure, clean_up_original_files,
    prompt_for_password, display_extraction_results, is_partial_archive,
    extract_partial_archive_and_reassemble, is_archive_file, get_ascii_temp_path,
    check_multipart_completeness, find_missing_parts_in_other_archives,
    extract_multipart_with_7z
)


def process_paths(paths: List[Path], recursive: bool = False, verbose: bool = False, 
                 dry_run: bool = False, no_extract: bool = False) -> None:
    """Process the provided paths for unzipping operations.
    
    Args:
        paths: List of validated Path objects (files or directories)
        recursive: Whether to recursively search directories
        verbose: Whether to show detailed information
        dry_run: Whether to simulate renaming without actually doing it
        no_extract: Whether to skip archive extraction (extraction is default)
    """
    safe_print(f"Complex Unzip Tool v2 - Processing {len(paths)} path(s)")
    safe_print(f"Â§çÊùÇËß£ÂéãÂ∑•ÂÖ∑ v2 - Ê≠£Âú®Â§ÑÁêÜ {len(paths)} ‰∏™Ë∑ØÂæÑ")
    safe_print("‚úì No cloaked files detected | Êú™Ê£ÄÊµãÂà∞‰º™Ë£ÖÊñá‰ª∂")
    
    # Determine root path from the first path
    root_path = paths[0].parent if paths[0].is_file() else paths[0]
    
    # Collect all files from paths
    all_files = collect_all_files(paths, recursive)
    
    # Load password book and determine save location
    passwords = load_password_book(root_path)
    
    # Determine best location for saving new passwords
    possible_save_locations = [
        Path.cwd() / "passwords.txt",  # Current working directory (project dir) - preferred
        root_path / "passwords.txt",  # Target directory
    ]
    
    passwords_file = None
    for location in possible_save_locations:
        try:
            # Test if we can write to this location
            if location.exists() or location.parent.exists():
                passwords_file = location
                break
        except Exception:
            continue
    
    if not passwords_file:
        passwords_file = Path.cwd() / "passwords.txt"  # Fallback to current directory
    
    if verbose:
        safe_print("\nüìã All files found | ÊâæÂà∞ÁöÑÊâÄÊúâÊñá‰ª∂:")
        for file_path in sorted(all_files):
            safe_print(f"   üìÑ {file_path}")
        
        # Display password information if verbose
        display_password_info(passwords, verbose=True)
    
    # Group files by subfolder
    subfolder_groups = group_files_by_subfolder(all_files)
    
    # Group files with root-aware priority logic
    priority_groups = group_files_by_priority(all_files, root_path)
    
    # Display the groups
    display_file_groups(subfolder_groups, priority_groups, verbose)
    
    # Perform extraction by default (unless disabled or dry-run)
    if not no_extract and not dry_run:
        safe_print("\n" + "=" * 60)
        safe_print("üöÄ STARTING ARCHIVE EXTRACTION | ÂºÄÂßãÂéãÁº©Êñá‰ª∂Ëß£Âéã")
        safe_print("=" * 60)
        
        extraction_result = ExtractionResult()
        completed_dir = root_path / "completed"
        passwords_file = root_path / "passwords.txt"
        
        # Track archives that have been processed to avoid duplicate processing
        processed_archives = set()
        
        # Track container archives that should be cleaned up after successful extraction
        containers_to_cleanup = set()
        
        # Process each group in priority_groups, but prioritize groups with partial archives first
        groups_to_process = list(priority_groups.items())
        
        safe_print(f"\nüîç Analyzing groups for partial archive priority...")
        
        # Sort groups to prioritize those containing partial archives
        def group_priority(group_item):
            group_name, group_files = group_item
            # Check if any file in this group might contain partial archive content
            for file_path in group_files:
                if is_archive_file(file_path, strict=True):
                    # Quick heuristic checks first
                    file_name = file_path.name.lower()
                    
                    # If filename suggests it might be a single part of something, prioritize it
                    if any(indicator in file_name for indicator in ['11111', 'part', 'vol', 'disc']):
                        safe_print(f"  üß© Priority: {group_name} might contain partial content: {file_path.name}")
                        return 0
                    
                    # Try actual detection with very short timeout
                    try:
                        # Use ASCII temp path for the detection to avoid encoding issues
                        temp_file, needs_cleanup = get_ascii_temp_path(file_path)
                        try:
                            is_partial, base_name = is_partial_archive(temp_file)
                            if is_partial:
                                safe_print(f"  üß© Priority: {group_name} contains partial archive: {file_path.name}")
                                return 0  # High priority for partial archives
                        finally:
                            if needs_cleanup and temp_file.exists():
                                try:
                                    temp_file.unlink()
                                except Exception:
                                    pass
                    except Exception as e:
                        safe_print(f"  ‚ö†Ô∏è Error checking {file_path.name}: {e}")
                        # If we can't check, but the name suggests partial content, prioritize anyway
                        if any(indicator in file_name for indicator in ['11111', 'part', 'vol']):
                            return 0
                        continue
            return 1  # Lower priority for regular archives
        
        groups_to_process.sort(key=group_priority)
        
        for group_name, group_files in groups_to_process:
            safe_print(f"\nüì¶ Processing group: {group_name} | Â§ÑÁêÜÁªÑ: {group_name}")
            safe_print("-" * 40)
            
            # Find the main archive to extract
            main_archive = find_main_archive_in_group(group_files)
            
            if not main_archive:
                safe_print(f"  ‚ùå No main archive found in group | ÁªÑ‰∏≠Êú™ÊâæÂà∞‰∏ªÂéãÁº©Êñá‰ª∂")
                extraction_result.failed_extractions.append((group_name, "No main archive found"))
                continue
            
            # Check if this archive was already processed as a container
            if main_archive in processed_archives:
                safe_print(f"  ‚è≠Ô∏è Archive already processed as container, skipping: {main_archive.name}")
                continue
            
            safe_print(f"  üéØ Main archive: {main_archive.name}")
            
            # Check if this is a multi-part archive and if it's complete
            is_multipart = False
            is_complete = False
            base_name = ""
            if re.match(r'.*\.001$', main_archive.name, re.IGNORECASE):
                is_multipart = True
                base_name = re.sub(r'\.001$', '', main_archive.name, flags=re.IGNORECASE)
                
                safe_print(f"  üß© Detected multi-part archive: {base_name}")
                
                # Check completeness
                is_complete, found_parts, missing_parts = check_multipart_completeness(group_files, base_name)
                
                if not is_complete:
                    safe_print(f"  ‚ö†Ô∏è Multi-part archive incomplete! Found parts: {found_parts}, Missing: {missing_parts}")
                    
                    # Look for missing parts in other archives
                    part_locations = find_missing_parts_in_other_archives(missing_parts, base_name, priority_groups)
                    
                    if part_locations:
                        safe_print(f"  üîç Found missing parts in other archives:")
                        for part_num, container_archive in part_locations.items():
                            safe_print(f"     Part {part_num:03d} found in: {container_archive.name}")
                        
                        # Extract the containers first to get the missing parts
                        extracted_any_parts = False
                        for part_num, container_archive in part_locations.items():
                            safe_print(f"  üì¶ Extracting container for part {part_num:03d}: {container_archive.name}")
                            
                            # Create temp directory for the container extraction
                            container_temp_dir = main_archive.parent / f"temp_container_{container_archive.stem}"
                            
                            try:
                                # For container extraction, always use regular extraction to get individual files
                                # Don't try to reassemble as multi-part archive - just extract contents
                                success, message, password_used = extract_with_7z(
                                    container_archive, container_temp_dir, passwords
                                )
                                
                                if success:
                                    safe_print(f"  ‚úÖ Extracted container successfully")
                                    extracted_any_parts = True
                                    
                                    # Mark this archive as processed to avoid processing it again later
                                    processed_archives.add(container_archive)
                                    
                                    # Mark this container for cleanup when main extraction succeeds
                                    containers_to_cleanup.add(container_archive)
                                    
                                    if password_used and password_used not in passwords:
                                        passwords.append(password_used)
                                        extraction_result.new_passwords.append(password_used)
                                    
                                    # Copy extracted missing parts to the main archive directory
                                    expected_part_name = f"{base_name}.{part_num:03d}"
                                    
                                    for extracted_file in container_temp_dir.rglob("*"):
                                        if extracted_file.is_file() and expected_part_name.lower() in extracted_file.name.lower():
                                            target_path = main_archive.parent / expected_part_name
                                            shutil.copy2(extracted_file, target_path)
                                            safe_print(f"  üìÑ Copied missing part: {expected_part_name}")
                                            break
                                    else:
                                        safe_print(f"  ‚ö†Ô∏è Missing part {expected_part_name} not found in container")
                                else:
                                    safe_print(f"  ‚ùå Failed to extract container: {message}")
                                    
                            except Exception as e:
                                safe_print(f"  ‚ùå Error extracting container: {e}")
                            finally:
                                # Clean up container temp directory
                                if container_temp_dir.exists():
                                    shutil.rmtree(container_temp_dir, ignore_errors=True)
                        
                        if not extracted_any_parts:
                            safe_print(f"  ‚ùå Failed to extract any missing parts from containers")
                            extraction_result.failed_extractions.append((group_name, "Failed to extract missing parts from containers"))
                            continue
                        
                        # Now re-check if we have all parts after extraction
                        safe_print(f"  üîÑ Re-checking completeness after container extraction...")
                        
                        # Rescan the directory to find all parts (including newly copied ones)
                        archive_dir = main_archive.parent
                        all_parts_in_dir = []
                        for file_path in archive_dir.iterdir():
                            if file_path.is_file() and base_name.lower() in file_path.name.lower() and re.search(r'\.\d{3}$', file_path.suffix):
                                all_parts_in_dir.append(file_path)
                        
                        is_complete, found_parts, missing_parts = check_multipart_completeness(all_parts_in_dir, base_name)
                        
                        if is_complete:
                            safe_print(f"  ‚úÖ Multi-part archive is now complete with parts: {found_parts}")
                            # Update the group files to include the newly found parts
                            group_files = all_parts_in_dir
                        else:
                            safe_print(f"  ‚ö†Ô∏è Multi-part archive still incomplete after container extraction. Found parts: {found_parts}, Missing: {missing_parts}")
                            extraction_result.failed_extractions.append((group_name, f"Multi-part archive incomplete after container extraction. Missing parts: {missing_parts}"))
                            continue
                        
                    else:
                        safe_print(f"  ‚ùå Missing parts not found in any other archives")
                        extraction_result.failed_extractions.append((group_name, f"Multi-part archive incomplete. Missing parts: {missing_parts}"))
                        continue
                else:
                    safe_print(f"  ‚úÖ Multi-part archive is complete with parts: {found_parts}")
            
            # Create temporary extraction directory
            temp_extract_dir = main_archive.parent / f"temp_extract_{group_name}"
            
            try:
                # Check if this is a partial archive that needs special handling
                # But skip partial archive logic if this is a complete multi-part archive
                is_partial, base_name_partial = is_partial_archive(main_archive)
                
                if is_partial and not (is_multipart and is_complete):
                    # This is a partial archive (not a complete multi-part archive)
                    safe_print(f"  üß© Detected partial archive content, extracting and reassembling...")
                    success, message, password_used = extract_partial_archive_and_reassemble(main_archive, temp_extract_dir, passwords)
                else:
                    # Regular archive extraction (including complete multi-part archives)
                    if is_multipart and is_complete:
                        # For multi-part archives, we need to handle all parts together
                        safe_print(f"  üß© Multi-part archive detected, handling all {len(group_files)} parts together")
                        success, message, password_used = extract_multipart_with_7z(group_files, temp_extract_dir, passwords)
                    else:
                        # Single archive extraction
                        success, message, password_used = extract_with_7z(main_archive, temp_extract_dir, passwords)
                
                # If extraction failed, prompt for password
                if not success and "password" in message.lower():
                    user_password = prompt_for_password(main_archive.name)
                    if user_password:
                        passwords.append(user_password)
                        if is_partial and not (is_multipart and is_complete):
                            success, message, password_used = extract_partial_archive_and_reassemble(main_archive, temp_extract_dir, [user_password])
                        else:
                            success, message, password_used = extract_with_7z(main_archive, temp_extract_dir, [user_password])
                        if success:
                            extraction_result.new_passwords.append(user_password)
                
                if success:
                    safe_print(f"  ‚úÖ Extracted main archive successfully")
                    
                    # Extract nested archives recursively
                    safe_print(f"  üîÑ Checking for nested archives...")
                    
                    final_files, new_passwords = extract_nested_archives(temp_extract_dir, passwords)
                    extraction_result.new_passwords.extend(new_passwords)
                    
                    # Copy files to completed directory
                    group_completed_dir = create_completed_structure(completed_dir, group_name, final_files)
                    extraction_result.completed_files.extend(final_files)
                    
                    # Clean up original files
                    deleted, failed = clean_up_original_files(group_files)
                    
                    # Also clean up container archives that were used for this group
                    containers_deleted = 0
                    containers_failed = 0
                    for container_archive in containers_to_cleanup:
                        try:
                            if container_archive.exists():
                                container_archive.unlink()
                                containers_deleted += 1
                                safe_print(f"  üóëÔ∏è  Cleaned up container: {container_archive.name}")
                        except Exception as e:
                            containers_failed += 1
                            safe_print(f"  ‚ùå Failed to clean up container {container_archive.name}: {e}")
                    
                    total_deleted = deleted + containers_deleted
                    total_failed = failed + containers_failed
                    safe_print(f"  üóëÔ∏è  Cleaned up: {total_deleted} files deleted, {total_failed} failed")
                    
                    # Clean up temporary directory
                    if temp_extract_dir.exists():
                        shutil.rmtree(temp_extract_dir, ignore_errors=True)
                    
                    extraction_result.successful_extractions.append((group_name, len(final_files)))
                    
                else:
                    safe_print(f"  ‚ùå Extraction failed: {message}")
                    extraction_result.failed_extractions.append((group_name, message))
                    
                    # Clean up failed extraction directory
                    if temp_extract_dir.exists():
                        shutil.rmtree(temp_extract_dir, ignore_errors=True)
                
            except Exception as e:
                safe_print(f"  ‚ùå Error processing group: {e}")
                extraction_result.failed_extractions.append((group_name, str(e)))
                
                # Clean up on error
                if temp_extract_dir.exists():
                    shutil.rmtree(temp_extract_dir, ignore_errors=True)
        
        # Save new passwords to password book
        if extraction_result.new_passwords:
            save_new_passwords(passwords_file, extraction_result.new_passwords)
        
        # Display final results
        display_extraction_results(extraction_result)
        
    elif not no_extract and dry_run:
        safe_print("\nüí° Extraction not performed in dry-run mode | È¢ÑÊºîÊ®°Âºè‰∏ã‰∏çÊâßË°åËß£Âéã")
        safe_print("üí° Use without --dry-run to perform actual extraction | ‰∏ç‰ΩøÁî® --dry-run ÊâßË°åÂÆûÈôÖËß£Âéã")
    elif no_extract:
        safe_print("\nüí° Extraction skipped (--no-extract specified) | Ë∑≥ËøáËß£ÂéãÔºàÊåáÂÆö‰∫Ü --no-extractÔºâ")
    
    # Display password book summary (non-verbose)
    if not verbose and passwords:
        display_password_info(passwords, verbose=False)
    
    safe_print("\n" + "-" * 50)
    safe_print("Processing complete! | Â§ÑÁêÜÂÆåÊàêÔºÅ")


def main():
    """Main entry point for the application."""
    parser = argparse.ArgumentParser(
        description="Complex Unzip Tool v2 - Advanced archive extraction and management tool\n"
                   "Â§çÊùÇËß£ÂéãÂ∑•ÂÖ∑ v2 - È´òÁ∫ßÂéãÁº©Êñá‰ª∂Ëß£ÂéãÂíåÁÆ°ÁêÜÂ∑•ÂÖ∑",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Features | ÂäüËÉΩ:
  * Automatic archive extraction with 7z.exe (default) | ‰ΩøÁî®7z.exeËá™Âä®Ëß£ÂéãÔºàÈªòËÆ§Ôºâ
  * Recursive directory processing (default) | ÈÄíÂΩíÁõÆÂΩïÂ§ÑÁêÜÔºàÈªòËÆ§Ôºâ
  * Automatic cloaked file renaming (*.001Âà† ‚Üí *.001) | Ëá™Âä®‰º™Ë£ÖÊñá‰ª∂ÈáçÂëΩÂêç
  * Password book loading from passwords.txt | ‰ªépasswords.txtÂä†ËΩΩÂØÜÁ†ÅÊú¨
  * Intelligent multi-part archive detection | Êô∫ËÉΩÂ§öÈÉ®ÂàÜÂéãÁº©Êñá‰ª∂Ê£ÄÊµã
  * Recursive nested archive extraction | ÈÄíÂΩíÂµåÂ•óÂéãÁº©Êñá‰ª∂Ëß£Âéã
  * Interactive password prompting | ‰∫§‰∫íÂºèÂØÜÁ†ÅÊèêÁ§∫
  * Automatic file organization to 'completed' folder | Ëá™Âä®Êñá‰ª∂Êï¥ÁêÜÂà∞'completed'Êñá‰ª∂Â§π
  * Bilingual interface (English/Chinese) | ÂèåËØ≠ÁïåÈù¢ÔºàËã±Êñá/‰∏≠ÊñáÔºâ

Examples | Á§∫‰æã:
  complex-unzip /path/to/archives                    # Extract all archives recursively (default) | ÈÄíÂΩíËß£ÂéãÊâÄÊúâÂéãÁº©Êñá‰ª∂ÔºàÈªòËÆ§Ôºâ
  complex-unzip --no-recursive /path/to/directory    # Only process files in the specified directory | ‰ªÖÂ§ÑÁêÜÊåáÂÆöÁõÆÂΩï‰∏≠ÁöÑÊñá‰ª∂
  complex-unzip --no-extract /path/to/directory      # Only analyze without extraction | ‰ªÖÂàÜÊûê‰∏çËß£Âéã
  complex-unzip --dry-run /path/to/directory         # Preview renaming without extraction | È¢ÑËßàÈáçÂëΩÂêç‰ΩÜ‰∏çËß£Âéã
  complex-unzip --verbose /path/to/directory         # Show detailed extraction info | ÊòæÁ§∫ËØ¶ÁªÜËß£Âéã‰ø°ÊÅØ
        """
    )
    
    parser.add_argument(
        "paths",
        nargs="*",
        help="One or more file paths or directory paths to process\n"
             "‰∏Ä‰∏™ÊàñÂ§ö‰∏™Ë¶ÅÂ§ÑÁêÜÁöÑÊñá‰ª∂Ë∑ØÂæÑÊàñÁõÆÂΩïË∑ØÂæÑ"
    )
    
    parser.add_argument(
        "-r", "--no-recursive",
        action="store_true",
        help="Disable recursive directory search (recursive is default)\n"
             "Á¶ÅÁî®ÈÄíÂΩíÁõÆÂΩïÊêúÁ¥¢ÔºàÈªòËÆ§‰∏∫ÈÄíÂΩíÔºâ"
    )
    
    parser.add_argument(
        "-o", "--output",
        type=str,
        help="Output directory for extracted files (optional)\n"
             "Ëß£ÂéãÊñá‰ª∂ÁöÑËæìÂá∫ÁõÆÂΩïÔºàÂèØÈÄâÔºâ"
    )
    
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Enable verbose output for detailed information\n"
             "ÂêØÁî®ËØ¶ÁªÜËæìÂá∫‰ª•Ëé∑ÂèñËØ¶ÁªÜ‰ø°ÊÅØ"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Simulate file renaming without actually renaming files (renaming is automatic)\n"
             "Ê®°ÊãüÊñá‰ª∂ÈáçÂëΩÂêçËÄå‰∏çÂÆûÈôÖÈáçÂëΩÂêçÊñá‰ª∂ÔºàÈáçÂëΩÂêçÊòØËá™Âä®ÁöÑÔºâ"
    )
    
    parser.add_argument(
        "--no-extract",
        action="store_true",
        help="Skip archive extraction (extraction is performed by default)\n"
             "Ë∑≥ËøáÂéãÁº©Êñá‰ª∂Ëß£ÂéãÔºàÈªòËÆ§ÊâßË°åËß£ÂéãÔºâ"
    )
    
    args = parser.parse_args()
    
    # Handle drag and drop scenario (when used as compiled EXE)
    # If no paths provided, show help but also check for interactive mode
    if not args.paths:
        # Check if running as compiled EXE and suggest drag and drop
        import sys
        if getattr(sys, 'frozen', False):
            # Running as compiled EXE
            safe_print("üñ±Ô∏è  Drag and Drop Mode | ÊãñÊãΩÊ®°Âºè")
            safe_print("=" * 50)
            safe_print("This tool supports drag and drop!")
            safe_print("Ê≠§Â∑•ÂÖ∑ÊîØÊåÅÊãñÊãΩÊìç‰ΩúÔºÅ")
            safe_print("")
            safe_print("To use:")
            safe_print("‰ΩøÁî®ÊñπÊ≥ïÔºö")
            safe_print("1. Drag files or folders onto this EXE file")
            safe_print("   Â∞ÜÊñá‰ª∂ÊàñÊñá‰ª∂Â§πÊãñÊãΩÂà∞Ê≠§ EXE Êñá‰ª∂‰∏ä")
            safe_print("2. Or run from command line with paths as arguments")
            safe_print("   Êàñ‰ªéÂëΩ‰ª§Ë°åËøêË°åÂπ∂Êèê‰æõË∑ØÂæÑÂèÇÊï∞")
            safe_print("")
            safe_print("For command line usage:")
            safe_print("ÂëΩ‰ª§Ë°åÁî®Ê≥ïÔºö")
            parser.print_help()
            safe_print("")
            input("Press Enter to exit | ÊåâÂõûËΩ¶ÈîÆÈÄÄÂá∫...")
        else:
            # Running in development mode
            parser.print_help()
        return
    
    # Show drag and drop confirmation for EXE mode
    import sys
    if getattr(sys, 'frozen', False) and len(args.paths) > 0:
        safe_print("üñ±Ô∏è  Files/folders received via drag and drop!")
        safe_print("üñ±Ô∏è  ÈÄöËøáÊãñÊãΩÊé•Êî∂Âà∞Êñá‰ª∂/Êñá‰ª∂Â§πÔºÅ")
        safe_print("=" * 50)
        for i, path in enumerate(args.paths, 1):
            safe_print(f"{i}. {path}")
        safe_print("=" * 50)
        safe_print("")
    
    if args.verbose:
        safe_print("Verbose mode enabled | ËØ¶ÁªÜÊ®°ÂºèÂ∑≤ÂêØÁî®")
        safe_print(f"Arguments | ÂèÇÊï∞: {vars(args)}")
    
    # Validate paths
    try:
        validated_paths = validate_paths(args.paths)
    except FileNotFoundError as e:
        safe_print(f"‚ùå Error: {e}")
        exit(1)
    
    # Determine recursive behavior (default is True, disabled by --no-recursive or -r)
    recursive = not args.no_recursive
    
    # Process the paths
    process_paths(validated_paths, recursive, args.verbose, args.dry_run, args.no_extract)
    
    # Pause for EXE mode so users can see results
    import sys
    if getattr(sys, 'frozen', False):
        safe_print("")
        safe_print("=" * 50)
        input("Press Enter to exit | ÊåâÂõûËΩ¶ÈîÆÈÄÄÂá∫...")


if __name__ == "__main__":
    main()
