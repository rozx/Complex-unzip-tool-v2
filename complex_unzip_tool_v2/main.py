"""
Complex Unzip Tool v2 - Advanced zip file management
å¤æ‚è§£å‹å·¥å…· v2 - é«˜çº§å‹ç¼©æ–‡ä»¶ç®¡ç†å·¥å…·

A sop                    i          safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶") else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")rename_errors:
            for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")
    
    if verbose:     safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶") else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")     for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")f rename_errors:
            for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")f rename_errors:
            for error in rename_errors:
                safe_print(error)
    else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")       safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶") else:
        safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")       safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")       safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")       safe_safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")icated bilingual tool for analyzing and grouping archive files.
"""

import argparse
import shutil
import sys
import os
import re
from pathlib import Path
from typing import List

# Fix Windows console encoding for Unicode characters
if sys.platform.startswith('win'):
    try:
        # Set UTF-8 code page for Windows console
        os.system('chcp 65001 >nul 2>&1')
    except Exception:
        pass

from .file_collector import collect_all_files
from .file_grouper import group_files_by_priority
from .display_utils import display_file_groups
from .path_validator import validate_paths
from .password_manager import load_password_book, display_password_info, save_new_passwords
from .file_renamer import detect_cloaked_files, rename_cloaked_files, display_rename_suggestions
from .console_utils import safe_print
from .archive_extractor import (
    ExtractionResult, find_main_archive_in_group, extract_with_7z, 
    extract_nested_archives, create_completed_structure, clean_up_original_files,
    prompt_for_password, display_extraction_results, is_partial_archive,
    extract_partial_archive_and_reassemble, is_archive_file, get_ascii_temp_path,
    check_multipart_completeness, find_missing_parts_in_other_archives,
    extract_multipart_with_7z
)


def process_paths(paths: List[Path], recursive: bool = False, verbose: bool = False, 
                 dry_run: bool = False, no_extract: bool = False) -> None:
    """Process the provided paths for unzipping operations.
    
    Args:
        paths: List of validated Path objects (files or directories)
        recursive: Whether to recursively search directories
        verbose: Whether to show detailed information
        dry_run: Whether to simulate renaming without actually doing it
        no_extract: Whether to skip archive extraction (extraction is default)
    """
    safe_print(f"Complex Unzip Tool v2 - Processing {len(paths)} path(s)")
    safe_print(f"å¤æ‚è§£å‹å·¥å…· v2 - æ­£åœ¨å¤„ç† {len(paths)} ä¸ªè·¯å¾„")
    
    # Determine root path from the first path
    root_path = paths[0].parent if paths[0].is_file() else paths[0]
    
    # Collect all files from paths
    all_files = collect_all_files(paths, recursive)
    
    # Detect and rename cloaked files
    cloaked_files = detect_cloaked_files(all_files)
    if cloaked_files:
        safe_print(f"\nğŸ” Detected {len(cloaked_files)} cloaked files | æ£€æµ‹åˆ° {len(cloaked_files)} ä¸ªä¼ªè£…æ–‡ä»¶")
        if verbose:
            display_rename_suggestions(cloaked_files)
        
        # Automatically rename cloaked files
        successful_renames, rename_errors = rename_cloaked_files(cloaked_files, dry_run=False)
        if rename_errors:
            safe_print("âš ï¸ Some files could not be renamed | éƒ¨åˆ†æ–‡ä»¶æ— æ³•é‡å‘½å:")
            for error in rename_errors:
                safe_print(f"  âŒ {error}")
        elif successful_renames:
            safe_print("âœ… All cloaked files renamed successfully | æ‰€æœ‰ä¼ªè£…æ–‡ä»¶é‡å‘½åæˆåŠŸ")
        
        # Re-collect files after renaming
        all_files = collect_all_files(paths, recursive)
    else:
        safe_print("âœ“ No cloaked files detected | æœªæ£€æµ‹åˆ°ä¼ªè£…æ–‡ä»¶")
    
    # Load password book and determine save location
    passwords = load_password_book(root_path)
    
    # Determine best location for saving new passwords
    possible_save_locations = [
        Path.cwd() / "passwords.txt",  # Current working directory (project dir) - preferred
        root_path / "passwords.txt",  # Target directory
    ]
    
    passwords_file = None
    for location in possible_save_locations:
        try:
            # Test if we can write to this location
            if location.exists() or location.parent.exists():
                passwords_file = location
                break
        except Exception:
            continue
    
    if not passwords_file:
        passwords_file = Path.cwd() / "passwords.txt"  # Fallback to current directory
    
    if verbose:
        safe_print("\nğŸ“‹ All files found | æ‰¾åˆ°çš„æ‰€æœ‰æ–‡ä»¶:")
        for file_path in sorted(all_files):
            safe_print(f"   ğŸ“„ {file_path}")
        
        # Display password information if verbose
        display_password_info(passwords, verbose=True)
    
    # Group files with root-aware priority logic
    priority_groups = group_files_by_priority(all_files, root_path)
    
    # Display the groups
    display_file_groups(priority_groups, verbose)
    
    # Perform extraction by default (unless disabled or dry-run)
    if not no_extract and not dry_run:
        safe_print("\n" + "=" * 60)
        safe_print("ğŸš€ STARTING ARCHIVE EXTRACTION | å¼€å§‹å‹ç¼©æ–‡ä»¶è§£å‹")
        safe_print("=" * 60)
        
        extraction_result = ExtractionResult()
        completed_dir = root_path / "_Unzipped"
        passwords_file = root_path / "passwords.txt"
        
        # Track archives that have been processed to avoid duplicate processing
        processed_archives = set()
        
        # Track container archives that should be cleaned up after successful extraction
        containers_to_cleanup = set()
        
        # Track subfolders that have been successfully processed for cleanup
        processed_subfolders = set()
        
        # Process each group in priority_groups, but prioritize groups with partial archives first
        groups_to_process = list(priority_groups.items())
        
        safe_print(f"\nğŸ” Analyzing groups for partial archive priority... | åˆ†æç»„ä»¥ç¡®å®šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶ä¼˜å…ˆçº§...")
        
        # Sort groups to prioritize those containing partial archives
        def group_priority(group_item):
            group_name, group_files = group_item
            # Check if any file in this group might contain partial archive content
            for file_path in group_files:
                if is_archive_file(file_path):
                    # Quick heuristic checks first
                    file_name = file_path.name.lower()
                    
                    # If filename suggests it might be a single part of something, prioritize it
                    if any(indicator in file_name for indicator in ['11111', 'part', 'vol', 'disc']):
                        safe_print(f"  ğŸ§© Priority: {group_name} might contain partial content: {file_path.name} | ä¼˜å…ˆçº§: {group_name} å¯èƒ½åŒ…å«éƒ¨åˆ†å†…å®¹: {file_path.name}")
                        return 0
                    
                    # Try actual detection with very short timeout
                    try:
                        # Use ASCII temp path for the detection to avoid encoding issues
                        temp_file, needs_cleanup = get_ascii_temp_path(file_path)
                        try:
                            is_partial, base_name = is_partial_archive(temp_file)
                            if is_partial:
                                safe_print(f"  ğŸ§© Priority: {group_name} contains partial archive: {file_path.name} | ä¼˜å…ˆçº§: {group_name} åŒ…å«éƒ¨åˆ†å‹ç¼©æ–‡ä»¶: {file_path.name}")
                                return 0  # High priority for partial archives
                        finally:
                            if needs_cleanup and temp_file.exists():
                                try:
                                    temp_file.unlink()
                                except Exception:
                                    pass
                    except Exception as e:
                        safe_print(f"  âš ï¸ Error checking {file_path.name}: {e} | æ£€æŸ¥æ—¶å‡ºé”™ {file_path.name}: {e}")
                        # If we can't check, but the name suggests partial content, prioritize anyway
                        if any(indicator in file_name for indicator in ['11111', 'part', 'vol']):
                            return 0
                        continue
            return 1  # Lower priority for regular archives
        
        groups_to_process.sort(key=group_priority)
        
        for group_name, group_files in groups_to_process:
            safe_print(f"\nğŸ“¦ Processing group: {group_name} | å¤„ç†ç»„: {group_name}")
            safe_print("-" * 40)
            
            # Find the main archive to extract
            main_archive = find_main_archive_in_group(group_files)
            
            if not main_archive:
                safe_print(f"  âŒ No main archive found in group | ç»„ä¸­æœªæ‰¾åˆ°ä¸»å‹ç¼©æ–‡ä»¶")
                extraction_result.failed_extractions.append((group_name, "No main archive found"))
                continue
            
            # Check if this archive was already processed as a container
            if main_archive in processed_archives:
                safe_print(f"  â­ï¸ Archive already processed as container, skipping: {main_archive.name} | å‹ç¼©æ–‡ä»¶å·²ä½œä¸ºå®¹å™¨å¤„ç†ï¼Œè·³è¿‡: {main_archive.name}")
                continue
            
            safe_print(f"  ğŸ¯ Main archive: {main_archive.name} | ä¸»å‹ç¼©æ–‡ä»¶: {main_archive.name}")
            
            # Check if this is a multi-part archive and if it's complete
            is_multipart = False
            is_complete = False
            base_name = ""
            if re.match(r'.*\.001$', main_archive.name, re.IGNORECASE):
                is_multipart = True
                base_name = re.sub(r'\.001$', '', main_archive.name, flags=re.IGNORECASE)
                
                safe_print(f"  ğŸ§© Detected multi-part archive: {base_name} | æ£€æµ‹åˆ°å¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶: {base_name}")
                
                # Check completeness
                is_complete, found_parts, missing_parts = check_multipart_completeness(group_files, base_name)
                
                if not is_complete:
                    safe_print(f"  âš ï¸ Multi-part archive incomplete! Found parts: {found_parts}, Missing: {missing_parts} | å¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶ä¸å®Œæ•´ï¼æ‰¾åˆ°éƒ¨åˆ†: {found_parts}ï¼Œç¼ºå°‘: {missing_parts}")
                    
                    # Look for missing parts in other archives
                    part_locations = find_missing_parts_in_other_archives(missing_parts, base_name, priority_groups)
                    
                    if part_locations:
                        safe_print(f"  ğŸ” Found missing parts in other archives: | åœ¨å…¶ä»–å‹ç¼©æ–‡ä»¶ä¸­æ‰¾åˆ°ç¼ºå°‘çš„éƒ¨åˆ†:")
                        for part_num, container_archive in part_locations.items():
                            safe_print(f"     Part {part_num:03d} found in: {container_archive.name} | éƒ¨åˆ† {part_num:03d} åœ¨æ­¤æ‰¾åˆ°: {container_archive.name}")
                        
                        # Extract the containers first to get the missing parts
                        extracted_any_parts = False
                        for part_num, container_archive in part_locations.items():
                            safe_print(f"  ğŸ“¦ Extracting container for part {part_num:03d}: {container_archive.name} | ä¸ºéƒ¨åˆ† {part_num:03d} è§£å‹å®¹å™¨: {container_archive.name}")
                            
                            # Create temp directory for the container extraction
                            container_temp_dir = main_archive.parent / f"temp_container_{container_archive.stem}"
                            
                            try:
                                # For container extraction, always use regular extraction to get individual files
                                # Don't try to reassemble as multi-part archive - just extract contents
                                success, message, password_used = extract_with_7z(
                                    container_archive, container_temp_dir, passwords
                                )
                                
                                if success:
                                    safe_print(f"  âœ… Extracted container successfully | å®¹å™¨è§£å‹æˆåŠŸ")
                                    extracted_any_parts = True
                                    
                                    # Mark this archive as processed to avoid processing it again later
                                    processed_archives.add(container_archive)
                                    
                                    # Mark this container for cleanup when main extraction succeeds
                                    containers_to_cleanup.add(container_archive)
                                    
                                    if password_used and password_used not in passwords:
                                        passwords.append(password_used)
                                        extraction_result.new_passwords.append(password_used)
                                    
                                    # Copy extracted missing parts to the main archive directory
                                    expected_part_name = f"{base_name}.{part_num:03d}"
                                    
                                    for extracted_file in container_temp_dir.rglob("*"):
                                        if extracted_file.is_file() and expected_part_name.lower() in extracted_file.name.lower():
                                            target_path = main_archive.parent / expected_part_name
                                            shutil.copy2(extracted_file, target_path)
                                            safe_print(f"  ğŸ“„ Copied missing part: {expected_part_name} | å¤åˆ¶ç¼ºå°‘çš„éƒ¨åˆ†: {expected_part_name}")
                                            break
                                    else:
                                        safe_print(f"  âš ï¸ Missing part {expected_part_name} not found in container | å®¹å™¨ä¸­æœªæ‰¾åˆ°ç¼ºå°‘çš„éƒ¨åˆ† {expected_part_name}")
                                else:
                                    safe_print(f"  âŒ Failed to extract container: {message} | è§£å‹å®¹å™¨å¤±è´¥: {message}")
                                    
                            except Exception as e:
                                safe_print(f"  âŒ Error extracting container: {e} | è§£å‹å®¹å™¨æ—¶å‡ºé”™: {e}")
                            finally:
                                # Clean up container temp directory
                                if container_temp_dir.exists():
                                    shutil.rmtree(container_temp_dir, ignore_errors=True)
                        
                        if not extracted_any_parts:
                            safe_print(f"  âŒ Failed to extract any missing parts from containers | ä»å®¹å™¨ä¸­è§£å‹ä»»ä½•ç¼ºå°‘éƒ¨åˆ†å¤±è´¥")
                            extraction_result.failed_extractions.append((group_name, "Failed to extract missing parts from containers"))
                            continue
                        
                        # Now re-check if we have all parts after extraction
                        safe_print(f"  ğŸ”„ Re-checking completeness after container extraction... | å®¹å™¨è§£å‹åé‡æ–°æ£€æŸ¥å®Œæ•´æ€§...")
                        
                        # Rescan the directory to find all parts (including newly copied ones)
                        archive_dir = main_archive.parent
                        all_parts_in_dir = []
                        for file_path in archive_dir.iterdir():
                            if file_path.is_file() and base_name.lower() in file_path.name.lower() and re.search(r'\.\d{3}$', file_path.suffix):
                                all_parts_in_dir.append(file_path)
                        
                        is_complete, found_parts, missing_parts = check_multipart_completeness(all_parts_in_dir, base_name)
                        
                        if is_complete:
                            safe_print(f"  âœ… Multi-part archive is now complete with parts: {found_parts} | å¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶ç°åœ¨å®Œæ•´ï¼ŒåŒ…å«éƒ¨åˆ†: {found_parts}")
                            # Update the group files to include the newly found parts
                            group_files = all_parts_in_dir
                        else:
                            safe_print(f"  âš ï¸ Multi-part archive still incomplete after container extraction. Found parts: {found_parts}, Missing: {missing_parts} | å®¹å™¨è§£å‹åå¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶ä»ä¸å®Œæ•´ã€‚æ‰¾åˆ°éƒ¨åˆ†: {found_parts}ï¼Œç¼ºå°‘: {missing_parts}")
                            extraction_result.failed_extractions.append((group_name, f"Multi-part archive incomplete after container extraction. Missing parts: {missing_parts}"))
                            continue
                        
                    else:
                        safe_print(f"  âŒ Missing parts not found in any other archives | åœ¨ä»»ä½•å…¶ä»–å‹ç¼©æ–‡ä»¶ä¸­éƒ½æœªæ‰¾åˆ°ç¼ºå°‘çš„éƒ¨åˆ†")
                        extraction_result.failed_extractions.append((group_name, f"Multi-part archive incomplete. Missing parts: {missing_parts}"))
                        continue
                else:
                    safe_print(f"  âœ… Multi-part archive is complete with parts: {found_parts} | å¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶å®Œæ•´ï¼ŒåŒ…å«éƒ¨åˆ†: {found_parts}")
            
            # Create temporary extraction directory
            temp_extract_dir = main_archive.parent / f"temp_extract_{group_name}"
            
            try:
                # Check if this is a partial archive that needs special handling
                # But skip partial archive logic if this is a complete multi-part archive
                is_partial, base_name_partial = is_partial_archive(main_archive)
                
                if is_partial and not (is_multipart and is_complete):
                    # This is a partial archive (not a complete multi-part archive)
                    safe_print(f"  ğŸ§© Detected partial archive content, extracting and reassembling... | æ£€æµ‹åˆ°éƒ¨åˆ†å‹ç¼©æ–‡ä»¶å†…å®¹ï¼Œæ­£åœ¨è§£å‹å’Œé‡æ–°ç»„è£…...")
                    success, message, password_used = extract_partial_archive_and_reassemble(main_archive, temp_extract_dir, passwords)
                else:
                    # Regular archive extraction (including complete multi-part archives)
                    if is_multipart and is_complete:
                        # For multi-part archives, we need to handle all parts together
                        safe_print(f"  ğŸ§© Multi-part archive detected, handling all {len(group_files)} parts together | æ£€æµ‹åˆ°å¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶ï¼Œæ­£åœ¨å¤„ç†æ‰€æœ‰ {len(group_files)} ä¸ªéƒ¨åˆ†")
                        success, message, password_used = extract_multipart_with_7z(group_files, temp_extract_dir, passwords)
                    else:
                        # Single archive extraction
                        success, message, password_used = extract_with_7z(main_archive, temp_extract_dir, passwords)
                
                # If extraction failed, prompt for password
                if not success and "password" in message.lower():
                    user_password = prompt_for_password(main_archive.name)
                    if user_password:
                        passwords.append(user_password)
                        if is_partial and not (is_multipart and is_complete):
                            success, message, password_used = extract_partial_archive_and_reassemble(main_archive, temp_extract_dir, [user_password])
                        else:
                            success, message, password_used = extract_with_7z(main_archive, temp_extract_dir, [user_password])
                        if success:
                            extraction_result.new_passwords.append(user_password)
                
                if success:
                    safe_print(f"  âœ… Extracted main archive successfully | ä¸»å‹ç¼©æ–‡ä»¶è§£å‹æˆåŠŸ")
                    
                    # Extract nested archives recursively
                    safe_print(f"  ğŸ”„ Checking for nested archives... | æ£€æŸ¥åµŒå¥—å‹ç¼©æ–‡ä»¶...")
                    
                    final_files, new_passwords = extract_nested_archives(temp_extract_dir, passwords)
                    extraction_result.new_passwords.extend(new_passwords)
                    
                    # Copy files to completed directory
                    group_completed_dir = create_completed_structure(completed_dir, group_name, final_files)
                    extraction_result.completed_files.extend(final_files)
                    
                    # Clean up original files
                    deleted, failed = clean_up_original_files(group_files)
                    
                    # Also clean up container archives that were used for this group
                    containers_deleted = 0
                    containers_failed = 0
                    for container_archive in containers_to_cleanup:
                        try:
                            if container_archive.exists():
                                container_archive.unlink()
                                containers_deleted += 1
                                safe_print(f"  ğŸ—‘ï¸  Cleaned up container: {container_archive.name} | æ¸…ç†å®¹å™¨: {container_archive.name}")
                        except Exception as e:
                            containers_failed += 1
                            safe_print(f"  âŒ Failed to clean up container {container_archive.name}: {e} | æ¸…ç†å®¹å™¨å¤±è´¥ {container_archive.name}: {e}")
                    
                    total_deleted = deleted + containers_deleted
                    total_failed = failed + containers_failed
                    safe_print(f"  ğŸ—‘ï¸  Cleaned up: {total_deleted} files deleted, {total_failed} failed | æ¸…ç†å®Œæˆ: {total_deleted} ä¸ªæ–‡ä»¶å·²åˆ é™¤ï¼Œ{total_failed} ä¸ªå¤±è´¥")
                    
                    # Clean up temporary directory
                    if temp_extract_dir.exists():
                        shutil.rmtree(temp_extract_dir, ignore_errors=True)
                    
                    extraction_result.successful_extractions.append((group_name, len(final_files)))
                    
                    # Track subfolder for cleanup if this group represents a subfolder
                    if not group_name.startswith("root_"):
                        # Extract subfolder name from group name (format: {folder_name}_{subgroup_name})
                        subfolder_name = group_name.split('_')[0]
                        if subfolder_name:
                            processed_subfolders.add(subfolder_name)
                    
                else:
                    # Clean up error message to remove verbose 7z output
                    clean_message = message
                    if "Cannot open the file as" in message and "archive" in message:
                        # Extract just the essential error information
                        clean_message = "File is not a valid archive or is corrupted | æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶æˆ–å·²æŸå"
                    elif "stdout:" in message and "stderr:" in message:
                        # Try to extract a more concise error message
                        lines = message.split('\n')
                        error_lines = [line.strip() for line in lines if line.strip() and 
                                     ('ERROR:' in line or 'ERRORS:' in line or 'Can\'t open' in line)]
                        if error_lines:
                            clean_message = error_lines[0].replace('ERROR: ', '').replace('ERRORS:', 'Errors:')
                        else:
                            clean_message = "Extraction failed | è§£å‹å¤±è´¥"
                    
                    safe_print(f"  âŒ Extraction failed: {clean_message}")
                    extraction_result.failed_extractions.append((group_name, clean_message))
                    
                    # Clean up failed extraction directory
                    if temp_extract_dir.exists():
                        shutil.rmtree(temp_extract_dir, ignore_errors=True)
                
            except Exception as e:
                safe_print(f"  âŒ Error processing group: {e} | å¤„ç†ç»„æ—¶å‡ºé”™: {e}")
                extraction_result.failed_extractions.append((group_name, str(e)))
                
                # Clean up on error
                if temp_extract_dir.exists():
                    shutil.rmtree(temp_extract_dir, ignore_errors=True)
        
        # Save new passwords to password book
        if extraction_result.new_passwords:
            save_new_passwords(passwords_file, extraction_result.new_passwords)
        
        # Clean up successfully processed subfolders
        if processed_subfolders:
            safe_print(f"\nğŸ—‚ï¸  Cleaning up successfully processed subfolders... | æ¸…ç†æˆåŠŸå¤„ç†çš„å­æ–‡ä»¶å¤¹...")
            subfolder_deleted = 0
            subfolder_failed = 0
            
            for subfolder_name in processed_subfolders:
                subfolder_path = root_path / subfolder_name
                if subfolder_path.exists() and subfolder_path.is_dir():
                    try:
                        # Check if subfolder is empty or only contains files we've processed
                        remaining_files = list(subfolder_path.rglob('*'))
                        remaining_files = [f for f in remaining_files if f.is_file()]
                        
                        if not remaining_files:
                            # Subfolder is empty, safe to delete
                            shutil.rmtree(subfolder_path)
                            subfolder_deleted += 1
                            safe_print(f"  ğŸ—‘ï¸  Deleted empty subfolder: {subfolder_name} | åˆ é™¤ç©ºå­æ–‡ä»¶å¤¹: {subfolder_name}")
                        else:
                            safe_print(f"  âš ï¸  Subfolder {subfolder_name} still contains {len(remaining_files)} files - skipping deletion | å­æ–‡ä»¶å¤¹ {subfolder_name} ä»åŒ…å« {len(remaining_files)} ä¸ªæ–‡ä»¶ - è·³è¿‡åˆ é™¤")
                    except Exception as e:
                        subfolder_failed += 1
                        safe_print(f"  âŒ Failed to delete subfolder {subfolder_name}: {e} | åˆ é™¤å­æ–‡ä»¶å¤¹å¤±è´¥ {subfolder_name}: {e}")
            
            if subfolder_deleted > 0 or subfolder_failed > 0:
                safe_print(f"  ğŸ—‚ï¸  Subfolder cleanup: {subfolder_deleted} deleted, {subfolder_failed} failed | å­æ–‡ä»¶å¤¹æ¸…ç†: {subfolder_deleted} ä¸ªå·²åˆ é™¤ï¼Œ{subfolder_failed} ä¸ªå¤±è´¥")
        
        # Display final results
        display_extraction_results(extraction_result)
        
    elif not no_extract and dry_run:
        safe_print("\nğŸ’¡ Extraction not performed in dry-run mode | é¢„æ¼”æ¨¡å¼ä¸‹ä¸æ‰§è¡Œè§£å‹")
        safe_print("ğŸ’¡ Use without --dry-run to perform actual extraction | ä¸ä½¿ç”¨ --dry-run æ‰§è¡Œå®é™…è§£å‹")
    elif no_extract:
        safe_print("\nğŸ’¡ Extraction skipped (--no-extract specified) | è·³è¿‡è§£å‹ï¼ˆæŒ‡å®šäº† --no-extractï¼‰")
    
    # Display password book summary (non-verbose)
    if not verbose and passwords:
        display_password_info(passwords, verbose=False)
    
    safe_print("\n" + "-" * 50)
    safe_print("Processing complete! | å¤„ç†å®Œæˆï¼")


def main():
    """Main entry point for the application."""
    parser = argparse.ArgumentParser(
        description="Complex Unzip Tool v2 - Advanced archive extraction and management tool\n"
                   "å¤æ‚è§£å‹å·¥å…· v2 - é«˜çº§å‹ç¼©æ–‡ä»¶è§£å‹å’Œç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Features | åŠŸèƒ½:
  * Automatic archive extraction with 7z.exe (default) | ä½¿ç”¨7z.exeè‡ªåŠ¨è§£å‹ï¼ˆé»˜è®¤ï¼‰
  * Recursive directory processing (default) | é€’å½’ç›®å½•å¤„ç†ï¼ˆé»˜è®¤ï¼‰
  * Automatic cloaked file renaming (*.001åˆ  â†’ *.001) | è‡ªåŠ¨ä¼ªè£…æ–‡ä»¶é‡å‘½å
  * Password book loading from passwords.txt | ä»passwords.txtåŠ è½½å¯†ç æœ¬
  * Intelligent multi-part archive detection | æ™ºèƒ½å¤šéƒ¨åˆ†å‹ç¼©æ–‡ä»¶æ£€æµ‹
  * Recursive nested archive extraction | é€’å½’åµŒå¥—å‹ç¼©æ–‡ä»¶è§£å‹
  * Interactive password prompting | äº¤äº’å¼å¯†ç æç¤º
  * Automatic file organization to 'completed' folder | è‡ªåŠ¨æ–‡ä»¶æ•´ç†åˆ°'completed'æ–‡ä»¶å¤¹
  * Bilingual interface (English/Chinese) | åŒè¯­ç•Œé¢ï¼ˆè‹±æ–‡/ä¸­æ–‡ï¼‰

Examples | ç¤ºä¾‹:
  complex-unzip /path/to/archives                    # Extract all archives recursively (default) | é€’å½’è§£å‹æ‰€æœ‰å‹ç¼©æ–‡ä»¶ï¼ˆé»˜è®¤ï¼‰
  complex-unzip --no-recursive /path/to/directory    # Only process files in the specified directory | ä»…å¤„ç†æŒ‡å®šç›®å½•ä¸­çš„æ–‡ä»¶
  complex-unzip --no-extract /path/to/directory      # Only analyze without extraction | ä»…åˆ†æä¸è§£å‹
  complex-unzip --dry-run /path/to/directory         # Preview renaming without extraction | é¢„è§ˆé‡å‘½åä½†ä¸è§£å‹
  complex-unzip --verbose /path/to/directory         # Show detailed extraction info | æ˜¾ç¤ºè¯¦ç»†è§£å‹ä¿¡æ¯
        """
    )
    
    parser.add_argument(
        "paths",
        nargs="*",
        help="One or more file paths or directory paths to process\n"
             "ä¸€ä¸ªæˆ–å¤šä¸ªè¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„"
    )
    
    parser.add_argument(
        "-r", "--no-recursive",
        action="store_true",
        help="Disable recursive directory search (recursive is default)\n"
             "ç¦ç”¨é€’å½’ç›®å½•æœç´¢ï¼ˆé»˜è®¤ä¸ºé€’å½’ï¼‰"
    )
    
    parser.add_argument(
        "-o", "--output",
        type=str,
        help="Output directory for extracted files (optional)\n"
             "è§£å‹æ–‡ä»¶çš„è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰"
    )
    
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Enable verbose output for detailed information\n"
             "å¯ç”¨è¯¦ç»†è¾“å‡ºä»¥è·å–è¯¦ç»†ä¿¡æ¯"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Simulate file renaming without actually renaming files (renaming is automatic)\n"
             "æ¨¡æ‹Ÿæ–‡ä»¶é‡å‘½åè€Œä¸å®é™…é‡å‘½åæ–‡ä»¶ï¼ˆé‡å‘½åæ˜¯è‡ªåŠ¨çš„ï¼‰"
    )
    
    parser.add_argument(
        "--no-extract",
        action="store_true",
        help="Skip archive extraction (extraction is performed by default)\n"
             "è·³è¿‡å‹ç¼©æ–‡ä»¶è§£å‹ï¼ˆé»˜è®¤æ‰§è¡Œè§£å‹ï¼‰"
    )
    
    args = parser.parse_args()
    
    # Handle drag and drop scenario (when used as compiled EXE)
    # If no paths provided, show help but also check for interactive mode
    if not args.paths:
        # Check if running as compiled EXE and suggest drag and drop
        import sys
        if getattr(sys, 'frozen', False):
            # Running as compiled EXE
            safe_print("ğŸ–±ï¸  Drag and Drop Mode | æ‹–æ‹½æ¨¡å¼")
            safe_print("=" * 50)
            safe_print("This tool supports drag and drop!")
            safe_print("æ­¤å·¥å…·æ”¯æŒæ‹–æ‹½æ“ä½œï¼")
            safe_print("")
            safe_print("To use:")
            safe_print("ä½¿ç”¨æ–¹æ³•ï¼š")
            safe_print("1. Drag files or folders onto this EXE file")
            safe_print("   å°†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹æ‹–æ‹½åˆ°æ­¤ EXE æ–‡ä»¶ä¸Š")
            safe_print("2. Or run from command line with paths as arguments")
            safe_print("   æˆ–ä»å‘½ä»¤è¡Œè¿è¡Œå¹¶æä¾›è·¯å¾„å‚æ•°")
            safe_print("")
            safe_print("For command line usage:")
            safe_print("å‘½ä»¤è¡Œç”¨æ³•ï¼š")
            parser.print_help()
            safe_print("")
            input("Press Enter to exit | æŒ‰å›è½¦é”®é€€å‡º...")
        else:
            # Running in development mode
            parser.print_help()
        return
    
    # Show drag and drop confirmation for EXE mode
    import sys
    if getattr(sys, 'frozen', False) and len(args.paths) > 0:
        safe_print("ğŸ–±ï¸  Files/folders received via drag and drop!")
        safe_print("ğŸ–±ï¸  é€šè¿‡æ‹–æ‹½æ¥æ”¶åˆ°æ–‡ä»¶/æ–‡ä»¶å¤¹ï¼")
        safe_print("=" * 50)
        for i, path in enumerate(args.paths, 1):
            safe_print(f"{i}. {path}")
        safe_print("=" * 50)
        safe_print("")
    
    if args.verbose:
        safe_print("Verbose mode enabled | è¯¦ç»†æ¨¡å¼å·²å¯ç”¨")
        safe_print(f"Arguments | å‚æ•°: {vars(args)}")
    
    # Validate paths
    try:
        validated_paths = validate_paths(args.paths)
    except FileNotFoundError as e:
        safe_print(f"âŒ Error: {e}")
        exit(1)
    
    # Determine recursive behavior (default is True, disabled by --no-recursive or -r)
    recursive = not args.no_recursive
    
    # Process the paths
    process_paths(validated_paths, recursive, args.verbose, args.dry_run, args.no_extract)
    
    # Pause for EXE mode so users can see results
    import sys
    if getattr(sys, 'frozen', False):
        safe_print("")
        safe_print("=" * 50)
        input("Press Enter to exit | æŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main()
